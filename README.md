# Commonsense Story Ending Generation
Project for CSC 594: Topics in AI: Advanced Deep Learning.

* [Course presentation video](https://drive.google.com/file/d/1bjyqaGZO7YDmgxQyvQ74JLSKCqcMA7pI/view?usp=sharing)
* [Write-up](https://github.com/erikmcguire/common_seg/blob/master/csc594-ADL/documents/csc594-810-mcguire_erik-project-report.pdf)

## Abstract

This is a reproduction of a previous work ([Sheng et al., 2019](https://arxiv.org/abs/1909.01326)) which studied the biases in text generated by language models. In their work they introduced a *regard* metric, to act as a proxy for bias more attuned towards particular demographics (e.g., *man* or *woman*) than conventional sentiment analysis. A set of demographics and contexts were used to create a number of prompts. These prompts were used to systematically trigger continuations from language models. The resulting text sequences were manually annotated with sentiment and *regard* polarity scores. Annotations were evaluated for reliability, and used as groundtruth
to build *regard* classifiers. Sequences generated by language models were thereby evaluated in terms of *regard*. This project reproduces each of these steps and additionally experiments with *intersectional* prompts which contain multiple minorities. While a number of questions in methodology arose, results of replication attempts were highly similar to the original work, lending credence to the paperâ€™s claims that a distinct metric for bias could be created and might allow for analyses which correlate better with human judgments.
